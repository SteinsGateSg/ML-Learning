{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59086a6f",
   "metadata": {},
   "source": [
    "# PyTorch-learning \"Hello World\"-FashionMNIST图像分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9177d",
   "metadata": {},
   "source": [
    "PyTorch官方推荐的\"Hello World!\"项目，让我们走一遍深度学习的完整流程\n",
    "- 加载数据\n",
    "- 指定设备\n",
    "- 定义模型\n",
    "- 定义损失函数和优化器\n",
    "- $Train$\n",
    "- $Test$\n",
    "- $Save$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8c45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.pardir)\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ad393",
   "metadata": {},
   "source": [
    "## 加载数据\n",
    "\n",
    "`PyTorch`有两个处理数据的核心组件，一个是`Dataset`, 一个是`DataLoader`  \n",
    "`Dataset`: 存储(样本, 标签)对  \n",
    "`DataLoader`: 从Dataset中取数据+打包管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b503882",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = \"../Dataset\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../Dataset\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "\"\"\"\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X : {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "\n",
    "X : [batch_size, channels, height, width]\n",
    "y : [batch_size]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e902c",
   "metadata": {},
   "source": [
    "## 指定设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddff4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420ef18",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7d4f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetWork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetWork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff7ac4",
   "metadata": {},
   "source": [
    "## 定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2ea989",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcae830",
   "metadata": {},
   "source": [
    "## $Train$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89946dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 计算损失函数值\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff649a",
   "metadata": {},
   "source": [
    "## $Test$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742bd766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564e57b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a84aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------\n",
      "loss: 2.317452 [   64/60000]\n",
      "loss: 2.301095 [ 6464/60000]\n",
      "loss: 2.288608 [12864/60000]\n",
      "loss: 2.271758 [19264/60000]\n",
      "loss: 2.254943 [25664/60000]\n",
      "loss: 2.229294 [32064/60000]\n",
      "loss: 2.231590 [38464/60000]\n",
      "loss: 2.204962 [44864/60000]\n",
      "loss: 2.204659 [51264/60000]\n",
      "loss: 2.167528 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 2.166876 \n",
      "\n",
      "Epoch 2\n",
      "------------------------------\n",
      "loss: 2.183429 [   64/60000]\n",
      "loss: 2.171997 [ 6464/60000]\n",
      "loss: 2.123540 [12864/60000]\n",
      "loss: 2.126591 [19264/60000]\n",
      "loss: 2.089655 [25664/60000]\n",
      "loss: 2.035301 [32064/60000]\n",
      "loss: 2.044190 [38464/60000]\n",
      "loss: 1.980362 [44864/60000]\n",
      "loss: 1.986578 [51264/60000]\n",
      "loss: 1.907993 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.911174 \n",
      "\n",
      "Epoch 3\n",
      "------------------------------\n",
      "loss: 1.949002 [   64/60000]\n",
      "loss: 1.918992 [ 6464/60000]\n",
      "loss: 1.809729 [12864/60000]\n",
      "loss: 1.830220 [19264/60000]\n",
      "loss: 1.751012 [25664/60000]\n",
      "loss: 1.694007 [32064/60000]\n",
      "loss: 1.686216 [38464/60000]\n",
      "loss: 1.600429 [44864/60000]\n",
      "loss: 1.628242 [51264/60000]\n",
      "loss: 1.509288 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.534664 \n",
      "\n",
      "Epoch 4\n",
      "------------------------------\n",
      "loss: 1.606738 [   64/60000]\n",
      "loss: 1.571684 [ 6464/60000]\n",
      "loss: 1.421992 [12864/60000]\n",
      "loss: 1.478246 [19264/60000]\n",
      "loss: 1.390310 [25664/60000]\n",
      "loss: 1.369819 [32064/60000]\n",
      "loss: 1.364096 [38464/60000]\n",
      "loss: 1.294679 [44864/60000]\n",
      "loss: 1.336416 [51264/60000]\n",
      "loss: 1.229293 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 1.259562 \n",
      "\n",
      "Epoch 5\n",
      "------------------------------\n",
      "loss: 1.337765 [   64/60000]\n",
      "loss: 1.323774 [ 6464/60000]\n",
      "loss: 1.156303 [12864/60000]\n",
      "loss: 1.251304 [19264/60000]\n",
      "loss: 1.150775 [25664/60000]\n",
      "loss: 1.165266 [32064/60000]\n",
      "loss: 1.172479 [38464/60000]\n",
      "loss: 1.112225 [44864/60000]\n",
      "loss: 1.155312 [51264/60000]\n",
      "loss: 1.070870 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.093035 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8495a8",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a02908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(),\"../models/FashionMNIST/FashionMNIST.pth\")\n",
    "print(\"Saved PyTorch Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288234e",
   "metadata": {},
   "source": [
    "## 加载保存的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aabe067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30385\\AppData\\Local\\Temp\\ipykernel_16200\\4103798215.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"../models/FashionMNIST/FashionMNIST.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetWork().to(device)\n",
    "model.load_state_dict(torch.load(\"../models/FashionMNIST/FashionMNIST.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5ee8e",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6896bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
