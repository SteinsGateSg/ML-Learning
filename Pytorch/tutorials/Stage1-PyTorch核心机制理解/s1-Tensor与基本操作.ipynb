{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b887d4b",
   "metadata": {},
   "source": [
    "# Tensor与基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "713e342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e893734",
   "metadata": {},
   "source": [
    "## 1. Tensor创建与初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4132ab82",
   "metadata": {},
   "source": [
    "### 直接创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0a420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "l1 = [[1, 2],[3, 4]]\n",
    "s1 = torch.tensor(l1)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd763cf",
   "metadata": {},
   "source": [
    "### 随机创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f468c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9256,  1.1340,  0.1422],\n",
      "        [-0.4552, -0.9432,  0.0841]])\n"
     ]
    }
   ],
   "source": [
    "tensor_random = torch.randn(2, 3)\n",
    "print(tensor_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafccb7",
   "metadata": {},
   "source": [
    "### 全0/1张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc6b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "----------------------------\n",
      "tensor([[0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(2, 3) # 输入形状\n",
    "zeros = torch.zeros(1, 4) # 同样输入形状\n",
    "print(ones)\n",
    "print(\"----------------------------\")\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db3363",
   "metadata": {},
   "source": [
    "### 从NumPy数组创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72801bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor_from_np = torch.from_numpy(np_arr)\n",
    "print(tensor_from_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ba077",
   "metadata": {},
   "source": [
    "### 从另一个tensor创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99dc15ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "s2 = torch.ones_like(s1)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eccddf",
   "metadata": {},
   "source": [
    "## 2. Tensor的属性\n",
    "张量属性描述了它们的形状、数据类型以及存储它们的设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311bc194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor_attri  = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor_attri.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor_attri.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor_attri.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684d8992",
   "metadata": {},
   "source": [
    "## 3. Tensor的基本操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1a9ed",
   "metadata": {},
   "source": [
    "### 标准的类 NumPy 索引和切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f3984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8c330",
   "metadata": {},
   "source": [
    "### cat和stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2b770",
   "metadata": {},
   "source": [
    "### item()\n",
    "`item()`是 `tensor` 的一个方法，用于将包含单个元素的 `tensor` 转换为 Python `标量`（如 int、float 等）。它的核心作用是提取 `tensor` 中唯一的元素值，方便在 Python 环境中使用（如打印、计算、保存等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5a6f079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36)\n"
     ]
    }
   ],
   "source": [
    "mat_item_pre = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]]).sum\n",
    "print(mat_item_pre())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "mat_item = mat_item_pre().item()\n",
    "print(mat_item)\n",
    "# mat_item_pre 是一个方法对象的引用\n",
    "# 它指向 sum 这个方法本身，但没有执行\n",
    "# 类似于 C++ 中的函数指针或 Python 中的可调用对象\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c5c68",
   "metadata": {},
   "source": [
    "### tensor的形状变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa11e58d",
   "metadata": {},
   "source": [
    "#### 1. view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07347a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "mat2:\n",
      "tensor([[1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# view的本质是 “重新解读” tensor 在内存中的存储方式，它不会修改 tensor 的元素本身，只会改变对元素的维度划分。\n",
    "mat = torch.tensor([[1, 2], [3, 4]])\n",
    "mat2 = mat.view(1, 4)\n",
    "print(f\"mat:\\n{mat}\")\n",
    "print(f\"mat2:\\n{mat2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d22ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat3:\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "# view中可以用-1表示 “该维度的大小由其他维度和总元素数自动计算”，无需手动计算\n",
    "mat3 = mat.view(4, -1)\n",
    "print(f\"mat3:\\n{mat3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b4e85",
   "metadata": {},
   "source": [
    "注意：view操作要求原 tensor 必须是在内存中连续存储，否则会直接报错。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86941135",
   "metadata": {},
   "source": [
    "#### 2. reshape\n",
    "\n",
    "reshape的核心作用与view一致：在不改变元素总数的前提下，重新定义 tensor 的维度结构。用法也一样\n",
    "\n",
    "但是reshape同时兼容了在内存中连续存储的tensor和非连续存储的tensor\n",
    "当原 tensor 是连续的：reshape的行为与view几乎一致，返回的是原 tensor 的 “视图”（共享内存，修改会相互影响）。\n",
    "当原 tensor 是非连续的：reshape会先自动创建一个连续的副本（复制数据），再重塑形状，返回的是副本（不共享内存，修改互不影响）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21b76b",
   "metadata": {},
   "source": [
    "#### 3. permute\n",
    "permute的作用是按照指定的顺序重新排列 tensor 的维度，例如将一个 3 维 tensor 的维度(0,1,2)调整为(2,0,1)，从而改变各维度的含义（如从 “通道 - 高 - 宽” 转为 “宽 - 通道 - 高”）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c726c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "mat = torch.arange(3 * 4).view(1, 3, 4)\n",
    "print(mat.shape)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9238929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0,  4,  8],\n",
      "         [ 1,  5,  9],\n",
      "         [ 2,  6, 10],\n",
      "         [ 3,  7, 11]]])\n"
     ]
    }
   ],
   "source": [
    "mat_per = mat.permute(0, 2, 1)\n",
    "print(mat_per.shape)\n",
    "print(mat_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e087a",
   "metadata": {},
   "source": [
    "permute不会修改 tensor 的元素值，只会改变维度的逻辑排列顺序，因此：\n",
    "- 元素总数不变（新 shape 的各维度乘积与原 shape 相同）；\n",
    "- 返回的是原 tensor 的视图（view），与原 tensor 共享内存（修改视图会影响原 tensor）。\n",
    "\n",
    "注意:permute会导致 tensor 非连续"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172b4e7",
   "metadata": {},
   "source": [
    "#### 4. transpose\n",
    "transpose的核心作用是将 tensor 中两个指定维度的位置互换，从而改变 tensor 的形状（但元素总数不变）。例如，对于一个 3 维 tensor (a, b, c)，交换维度 1 和 2 后，形状会变为(a, c, b)。\n",
    "\n",
    "```py\n",
    "# 函数式调用\n",
    "torch.transpose(input, dim0, dim1)\n",
    "\n",
    "# 方法式调用（更常用）\n",
    "tensor.transpose(dim0, dim1)\n",
    "```\n",
    "\n",
    "`dim0`和`dim1`：需要交换的两个维度的索引（从 0 开始），必须是合法的维度索引（例如，2 维 tensor 只能交换 0 和 1）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26370316",
   "metadata": {},
   "source": [
    "#### 5. squeeze和unsqueeze\n",
    "squeeze：移除大小为 1 的维度\n",
    "- squeeze的作用是删除 tensor 中所有（或指定）大小为 1 的维度，使 tensor 的形状更简洁（维度数量减少）。\n",
    "\n",
    "```py\n",
    "# 移除所有大小为1的维度\n",
    "tensor.squeeze()\n",
    "\n",
    "# 只移除指定维度（若该维度大小为1）\n",
    "tensor.squeeze(dim)\n",
    "```\n",
    "- `dim`：可选参数，指定要移除的维度索引（从 0 开始）。若该维度大小不为 1，操作无效（不会报错，返回原 tensor）。\n",
    "\n",
    "\n",
    "unsqueeze：插入大小为 1 的维度\n",
    "- unsqueeze的作用是在指定位置插入一个大小为 1 的新维度，使 tensor 的维度数量增加（常用于给 tensor “补维度” 以匹配模型输入要求）。\n",
    "  \n",
    "```py\n",
    "tensor.unsqueeze(dim)\n",
    "```\n",
    "\n",
    "- `dim`：必选参数，指定插入新维度的位置（索引），范围为[-n-1, n]（n为原 tensor 的维度数），负数表示从后往前数（例如dim=-1表示插入到最后一个维度之后）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e800a33",
   "metadata": {},
   "source": [
    "## autograd\n",
    "创建Tensor的时候有一个参数需要注意`requires_grad=True`, 这个参数可以追踪这个变量，从而便于后期求导(反向传播时用到)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51021dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建张量\n",
    "x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True)\n",
    "y = torch.tensor([[2., 2.], [2., 2.]])\n",
    "z = x * y + 3\n",
    "out = z.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1917db",
   "metadata": {},
   "source": [
    "这里x中的参数`requires_grad=True`, 所以可以看成变量了， 所以这里的计算过程就是\n",
    "$$\n",
    "x = \\left(\\begin{matrix}\n",
    "x_{11} & x_{12} \\\\\n",
    "x_{21} & x_{22} \n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "z = x * y + 3 = \\left(\n",
    "\\begin{matrix}\n",
    "2x_{11} + 3 & 2x_{12} + 3 \\\\\n",
    "2x_{21} + 3 & 2x_{22} + 3\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "out = z.mean() = \\left(\n",
    "\\begin{matrix}\n",
    "\\frac{2x_{11} + 3}{4} & \\frac{2x_{12} + 3}{4} \\\\\n",
    "\\frac{2x_{21} + 3}{4} & \\frac{2x_{22} + 3}{4}\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fef3ee",
   "metadata": {},
   "source": [
    "### 自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f0c908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动求导\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cc55d",
   "metadata": {},
   "source": [
    "这里`out.backward()`是一个动作，这个函数的设计目的不是返回梯度值，而是计算梯度并将其存储在相应张量的`.grad`属性中。\n",
    "\n",
    "当我们调用`out.backward()`的时候，PyTorch会：\n",
    "- 从`out`开始，沿着计算图反向传播\n",
    "- 计算`out`相对于所有`requires_grad=True`的叶子节点张量的梯度\n",
    "- 将计算出的梯度累加到这些张量的`.grad`属性上\n",
    "\n",
    "所以这里发生了这件事情\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{out}}{\\partial_{x_{ij}}} = \\left(\n",
    "\\begin{matrix}\n",
    "\\frac{\\partial_{\\frac{2x_{11} + 3}{4}}}{\\partial_{x_{11}}} & \\frac{\\partial_{\\frac{2x_{12} + 3}{4}}}{\\partial_{x_{12}}} \\\\\n",
    "\\frac{\\partial_{\\frac{2x_{21} + 3}{4}}}{\\partial_{x_{21}}} & \\frac{\\partial_{\\frac{2x_{22} + 3}{4}}}{\\partial_{x_{22}}}\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "最后结果就是$\\frac{1}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7b27631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa970b",
   "metadata": {},
   "source": [
    "### 练习：用autograd完成一个线性回归\n",
    "\n",
    "目标：用PyTorch的 Tensor + autograd, 从随机数据中学习一个$y = 3x + 2$的关系出来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad0e89",
   "metadata": {},
   "source": [
    "- step 1. 构造数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e331df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.randn(100, 1)\n",
    "y = 3 * x + 2 + 0.1 * torch.randn(100, 1) # 加一点小噪声"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370bcdb1",
   "metadata": {},
   "source": [
    "- step 2. 初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fa004d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(1, 1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79fd49",
   "metadata": {},
   "source": [
    "- step 3. 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a6701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 14.791001319885254\n",
      "20 0.009392197243869305\n",
      "40 0.007803839631378651\n",
      "60 0.007803605869412422\n",
      "80 0.007803606800734997\n",
      "100 0.007803606800734997\n",
      "120 0.007803606800734997\n",
      "140 0.007803606800734997\n",
      "160 0.007803606800734997\n",
      "180 0.007803606800734997\n",
      "w: 3.001180410385132 b: 2.003567934036255\n"
     ]
    }
   ],
   "source": [
    "for step in range(200):\n",
    "\n",
    "    # 前向传播\n",
    "    y_pred = x @ w + b\n",
    "    loss = ((y_pred - y) ** 2).mean()\n",
    "\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    # 参数更新（在 no_grad 下操作数值）\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "\n",
    "    # 梯度清零\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, loss.item())\n",
    "print(\"w:\", w.item(), \"b:\", b.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
